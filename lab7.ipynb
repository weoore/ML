{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0f41fe4c-c5db-4851-980d-a4f5bc201ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from imblearn.under_sampling import NearMiss\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.utils import resample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b8c6b08f-c75a-4cd5-bfdf-2c80e529b06c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_regress = pd.read_csv('D:\\python\\data\\kc_house_data3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "21f656b4-917e-41bf-bcf3-08d86d752517",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_classification = pd.read_csv('D:\\python\\data\\card_transdata4.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d31a369-f7fe-43db-8e95-a7508d070832",
   "metadata": {},
   "source": [
    "## Задание 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0ceb1d1c-a288-4362-b44d-108a8253d92f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_regress.drop('Unnamed: 0', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dde97677-98be-4724-b60a-d82f426b5638",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 14934 entries, 0 to 14933\n",
      "Data columns (total 21 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   id             14934 non-null  int64  \n",
      " 1   date           14934 non-null  int64  \n",
      " 2   price          14934 non-null  int64  \n",
      " 3   bedrooms       14934 non-null  int64  \n",
      " 4   bathrooms      14934 non-null  float64\n",
      " 5   sqft_living    14934 non-null  int64  \n",
      " 6   sqft_lot       14934 non-null  int64  \n",
      " 7   floors         14934 non-null  int64  \n",
      " 8   waterfront     14934 non-null  int64  \n",
      " 9   view           14934 non-null  int64  \n",
      " 10  condition      14934 non-null  int64  \n",
      " 11  grade          14934 non-null  int64  \n",
      " 12  sqft_above     14934 non-null  int64  \n",
      " 13  sqft_basement  14934 non-null  int64  \n",
      " 14  yr_built       14934 non-null  int64  \n",
      " 15  yr_renovated   14934 non-null  int64  \n",
      " 16  zipcode        14934 non-null  int64  \n",
      " 17  lat            14934 non-null  float64\n",
      " 18  long           14934 non-null  float64\n",
      " 19  sqft_living15  14934 non-null  int64  \n",
      " 20  sqft_lot15     14934 non-null  int64  \n",
      "dtypes: float64(3), int64(18)\n",
      "memory usage: 2.4 MB\n"
     ]
    }
   ],
   "source": [
    "data_regress.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8ea1adc3-23fb-4d10-ad74-385d8f2e2ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_reg = data_regress[\"price\"]\n",
    "X_reg = data_regress.drop([\"price\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "de933e66-4e62-4902-8588-7877990f39e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_reg, y_reg, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0b70277e-478e-4cb0-a2fc-2fd7a131f9b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\python\\venv\\lib\\site-packages\\keras\\src\\backend.py:1398: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "inputs = tf.keras.Input(shape=(20,))\n",
    "x = tf.keras.layers.Dense(64, activation=\"relu\")(inputs) #Dense - полносвязный слой\n",
    "x = tf.keras.layers.Dense(32, activation=\"linear\")(x)\n",
    "x = tf.keras.layers.Dropout(0.1)(x)\n",
    "x = tf.keras.layers.Dense(16, activation=\"relu\")(x)\n",
    "x = tf.keras.layers.Dropout(0.1)(x)\n",
    "outputs = tf.keras.layers.Dense(1, activation=\"linear\")(x)\n",
    "model_regression = tf.keras.Model(inputs=inputs, outputs=outputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7a0d64d2-9b20-4c56-8997-4ce27ec7423a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_regression.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001), loss=\"mae\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "78f6ac7b-19aa-4eb8-97b3-cb6766de65f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\python\\venv\\lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1df1a5e0a30>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_regression.fit(X_train, y_train, epochs=150, verbose=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "56190c08-3529-48f8-b561-1cc8ff73f7aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94/94 [==============================] - 0s 893us/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = model_regression.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "db8a1df7-d7f9-4c90-a419-c518170fcd9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "139552.39977402077\n",
      "-0.09033718218664544\n"
     ]
    }
   ],
   "source": [
    "print(mean_absolute_error(y_test, y_pred))\n",
    "print(r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee5a6965-4fc1-4809-86a8-710c08e7e8f4",
   "metadata": {},
   "source": [
    "## Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f2bea918-bd59-43d7-83d8-86b3db0d8212",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_classification.drop('Unnamed: 0', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5cb163f7-c982-4890-919a-f39077974f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_0 = data_classification[data_classification['fraud'] == 0]\n",
    "class_1 = data_classification[data_classification['fraud'] == 1]\n",
    "class_0_downsampled = resample(class_0, replace=False, n_samples=int(0.1 * len(class_0)), random_state=42)# Уменьшаем размер подвыборки для класса 0\n",
    "small_data_classification = pd.concat([class_0_downsampled, class_1])# Объединяем данные обратно\n",
    "data_classification = small_data_classification.sample(frac=1, random_state=42)# Перемешиваем данные, чтобы сохранить случайность"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d571d591-6ac6-4dd8-96a0-1444c183292f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 13088 entries, 252968 to 194398\n",
      "Data columns (total 8 columns):\n",
      " #   Column                          Non-Null Count  Dtype  \n",
      "---  ------                          --------------  -----  \n",
      " 0   distance_from_home              13088 non-null  float64\n",
      " 1   distance_from_last_transaction  13088 non-null  float64\n",
      " 2   ratio_to_median_purchase_price  13088 non-null  float64\n",
      " 3   repeat_retailer                 13088 non-null  float64\n",
      " 4   used_chip                       13088 non-null  float64\n",
      " 5   used_pin_number                 13088 non-null  float64\n",
      " 6   online_order                    13088 non-null  float64\n",
      " 7   fraud                           13088 non-null  float64\n",
      "dtypes: float64(8)\n",
      "memory usage: 920.2 KB\n"
     ]
    }
   ],
   "source": [
    "data_classification.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2ba3d319-8087-44cf-a8b4-715d46f288d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_classifier = data_classification[\"fraud\"]\n",
    "X_classifier = data_classification.drop([\"fraud\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5e7e6932-3230-4b49-8367-0f2c45c18d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_classifier, X_test_classifier, y_train_classifier, y_test_classifier = train_test_split(X_classifier, y_classifier, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ee0cec4c-1614-4cbf-9c28-b7b46e39ca17",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tf.keras.Input(shape=(7,))\n",
    "x = tf.keras.layers.Dense(128, activation=\"relu\")(inputs) #Dense - полносвязный слой\n",
    "x = tf.keras.layers.Dense(64, activation=\"linear\")(x)\n",
    "x = tf.keras.layers.Dropout(0.1)(x)\n",
    "x = tf.keras.layers.Dense(32, activation=\"relu\")(x)\n",
    "x = tf.keras.layers.Dropout(0.1)(x)\n",
    "outputs = tf.keras.layers.Dense(1, activation=\"linear\")(x)\n",
    "model_class = tf.keras.Model(inputs=inputs, outputs=outputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6e96f4c3-f232-43d1-81cb-8066912bf285",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_class.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001), loss=\"mae\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "eb604f3f-1b0b-4bf4-995e-50cac4443595",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1df1acf7610>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_class.fit(X_train_classifier, y_train_classifier, epochs=10, verbose=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8dd61c5a-6077-4884-8444-0fab7336302e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model_class.predict(X_test_classifier, verbose=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0119c37d-0c19-4ff2-998b-df3cf17fb9a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "\n",
    "y_pred_scaled = scaler.fit_transform(y_pred.reshape(-1, 1))\n",
    "\n",
    "y_pred_scaled = y_pred_scaled.flatten()\n",
    "\n",
    "rounded_predictions = np.round(y_pred_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c61f86fd-b54d-42f2-876d-49e2f90716f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.96      0.98      1663\n",
      "         1.0       0.97      1.00      0.99      2264\n",
      "\n",
      "    accuracy                           0.98      3927\n",
      "   macro avg       0.99      0.98      0.98      3927\n",
      "weighted avg       0.98      0.98      0.98      3927\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test_classifier, rounded_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "830ba603-298a-4847-b28a-bf7185add468",
   "metadata": {},
   "source": [
    "## MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "db28407e-36cf-4aba-a99f-7ddb11a21432",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class MLP:\n",
    "    def __init__(self, layer_sizes, activation_functions):\n",
    "        self.num_layers = len(layer_sizes)\n",
    "        self.layer_sizes = layer_sizes\n",
    "        self.activation_functions = activation_functions\n",
    "        self.weights = [np.random.randn(layer_sizes[i], layer_sizes[i-1]) for i in range(1, self.num_layers)]\n",
    "        self.biases = [np.random.randn(layer_sizes[i], 1) for i in range(1, self.num_layers)]\n",
    "\n",
    "    def _sigmoid(self, x):\n",
    "        return 1.0 / (1.0 + np.exp(-x))\n",
    "\n",
    "    def _sigmoid_derivative(self, x):\n",
    "        return self._sigmoid(x) * (1 - self._sigmoid(x))\n",
    "\n",
    "    def _tanh(self, x):\n",
    "        return np.tanh(x)\n",
    "\n",
    "    def _tanh_derivative(self, x):\n",
    "        return 1 - np.tanh(x)**2\n",
    "\n",
    "    def _relu(self, x):\n",
    "        return np.maximum(0, x)\n",
    "\n",
    "    def _relu_derivative(self, x):\n",
    "        return np.where(x > 0, 1, 0)\n",
    "\n",
    "    def _feed_forward(self, x):\n",
    "        # х-ый элеменет\n",
    "        activations = [x]\n",
    "        zs = []\n",
    "        for i in range(self.num_layers - 1):\n",
    "            weight = self.weights[i]\n",
    "            bias = self.biases[i]\n",
    "            activation_fn = self.activation_functions[i]\n",
    "            #умножаем матрицу весов на вектор активаций последнего слоя + вектор смещения\n",
    "            z = np.dot(weight, activations[-1]) + bias\n",
    "            zs.append(z)\n",
    "            if activation_fn == 'sigmoid':\n",
    "                a = self._sigmoid(z)\n",
    "            elif activation_fn == 'tanh':\n",
    "                a = self._tanh(z)\n",
    "            elif activation_fn == 'relu':\n",
    "                a = self._relu(z)\n",
    "            activations.append(a)\n",
    "        return activations, zs\n",
    "\n",
    "    def _backpropagate(self, x, y):\n",
    "        # накопление градиентов функции потерь по весам и смещениям в каждом слое сети\n",
    "        delta_weights = [np.zeros(weight.shape) for weight in self.weights]\n",
    "        delta_biases = [np.zeros(bias.shape) for bias in self.biases]\n",
    "        # прямой проход сети для входных данных x, и сохраняются активации и взвешенные суммы для каждого слоя \n",
    "        activations, zs = self._feed_forward(x)\n",
    "        #разница между предсказанными активациями и фактическими значениями целевой переменной\n",
    "        delta = (activations[-1] - y) \n",
    "        for i in range(self.num_layers - 2, -1, -1):\n",
    "            # Получение взвешенной суммы\n",
    "            z = zs[i]\n",
    "            activation_fn = self.activation_functions[i]\n",
    "            if activation_fn == 'sigmoid':\n",
    "                derivative = self._sigmoid_derivative(z)\n",
    "            elif activation_fn == 'tanh':\n",
    "                derivative = self._tanh_derivative(z)\n",
    "            elif activation_fn == 'relu':\n",
    "                derivative = self._relu_derivative(z)\n",
    "            #Вычисление градиента по весам для текущего слоя\n",
    "            delta_weights[i] = np.dot(delta, activations[i].T)\n",
    "            delta_biases[i] = delta\n",
    "            delta = np.dot(self.weights[i].T, delta) * derivative\n",
    "        return delta_weights, delta_biases\n",
    "\n",
    "    def fit(self, X_train, y_train, learning_rate, num_epochs):\n",
    "        for epoch in range(num_epochs):\n",
    "            for x, y in zip(X_train, y_train):\n",
    "                x = np.array(x, ndmin=2).T\n",
    "                y = np.array(y, ndmin=2).T\n",
    "                delta_weights, delta_biases = self._backpropagate(x, y)\n",
    "                self.weights = [weight - learning_rate * d_weight for weight, d_weight in zip(self.weights, delta_weights)]\n",
    "                self.biases = [bias - learning_rate * d_bias for bias, d_bias in zip(self.biases, delta_biases)]\n",
    "\n",
    "    def predict(self, X_test):\n",
    "        predictions = []\n",
    "        for x in X_test:\n",
    "            # массив минимум 2мерный и транспонируем\n",
    "            x = np.array(x, ndmin=2).T\n",
    "            activations, _ = self._feed_forward(x)\n",
    "            predictions.append(activations[-1])\n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "cbb743c4-57cb-4042-ae0e-e30c7a74bfe2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Сабака\\AppData\\Local\\Temp\\ipykernel_2076\\3666063162.py:12: RuntimeWarning: overflow encountered in exp\n",
      "  return 1.0 / (1.0 + np.exp(-x))\n"
     ]
    }
   ],
   "source": [
    "X_train_regression = np.asarray(X_train, dtype=np.float64)\n",
    "y_train_regression = np.asarray(y_train, dtype=np.float64).reshape(-1, 1)\n",
    "\n",
    "mlp_regression = MLP([20, 1, 1], ['sigmoid', 'sigmoid'])\n",
    "\n",
    "# Обучаем модель\n",
    "mlp_regression.fit(X_train_regression, y_train_regression, learning_rate=0.05, num_epochs=10)\n",
    "\n",
    "X_test_regression = np.asarray(X_test, dtype=np.float64)\n",
    "# Получаем предсказания модели\n",
    "predictions_regression = mlp_regression.predict(X_test_regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "18968b24-fcaf-4b40-a693-12368fdfe0dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_regression = np.asarray(predictions_regression, dtype=np.float64).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "51248fc4-c962-4007-b1dc-99f91e3bcf11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "436396.0060261132\n",
      "221555161639.6063\n",
      "-6.120826201761699\n"
     ]
    }
   ],
   "source": [
    "y_test_regression = np.asarray(y_test, dtype=np.float64).reshape(-1, 1)\n",
    "from sklearn.metrics import r2_score\n",
    "print(mean_absolute_error(y_test_regression, predictions_regression))\n",
    "print(mean_squared_error(y_test_regression, predictions_regression))\n",
    "print(r2_score(y_test_regression, predictions_regression))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a9567912-3d2c-4af8-a144-7c5998db696d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# классификация "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ff89fedd-f119-4166-88d5-28fd53b787f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_classifier = np.asarray(X_train_classifier, dtype=np.float64)\n",
    "y_train_classifier = np.asarray(y_train_classifier, dtype=np.float64).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "bd4fe7f4-ec4c-4a49-b147-091740fa8e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_classifier = MLP([7, 1, 1, 1], ['tanh', 'relu', 'sigmoid'])\n",
    "\n",
    "mlp_classifier.fit(X_train_classifier, y_train_classifier, learning_rate=0.05, num_epochs=10)\n",
    "\n",
    "X_test_classifier = np.asarray(X_test_classifier, dtype=np.float64)\n",
    "# Получаем предсказания модели\n",
    "predictions_classifier = mlp_classifier.predict(X_test_classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f35a35dc-3680-4727-8c45-02ddf38338d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_classifier = np.asarray(predictions_classifier, dtype=np.float64).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a942ea7-fff7-434d-90e8-06a1a703e7db",
   "metadata": {},
   "outputs": [],
   "source": [
    "rounded_predictions = np.round(predictions_classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ba0702e7-a333-4168-84a4-b9f10703e739",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5765215176979883\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy = accuracy_score(y_test_classifier,rounded_predictions[:3927])\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
